{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cQcJqftemK03",
        "outputId": "cdaf921d-1a81-4684-f630-818c38bb17a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# 1. Configuration & Path Setup\n",
        "# ==============================================\n",
        "BASE_DIR = \"/content/drive/MyDrive/data\"  # Data Folder path\n",
        "CITIES = [f for f in os.listdir(BASE_DIR)\n",
        "          if os.path.isdir(os.path.join(BASE_DIR, f))\n",
        "          and not f.startswith('.')]  # Exclude hidden files\n",
        "\n",
        "DATE_RANGES = {\n",
        "    \"2023-12\": (\"2024-01-01\", \"2024-03-31\"),\n",
        "    \"2024-03\": (\"2024-04-01\", \"2024-06-30\"),\n",
        "    \"2024-06\": (\"2024-07-01\", \"2024-09-30\"),\n",
        "    \"2024-09\": (\"2024-10-01\", \"2024-12-31\")\n",
        "}"
      ],
      "metadata": {
        "id": "QS-rY8pXumWJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# 2. Calendar Data Processing\n",
        "# ==============================================\n",
        "def process_calendar(city_folder: str) -> pd.DataFrame:\n",
        "    \"\"\"Process calendar data with strict 4-period validation\"\"\"\n",
        "    calendar_files = sorted(glob.glob(os.path.join(city_folder, \"calendar*.csv\")))\n",
        "\n",
        "    # 1. Validate exactly 4 period files exist\n",
        "    if len(calendar_files) != 4:\n",
        "        print(f\"⚠️ Invalid file count in {city_folder}: {len(calendar_files)}/4 files found\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # 2. Two-pass processing for strict validation\n",
        "    # First pass: Collect IDs from all periods\n",
        "    period_ids = []\n",
        "    for file in calendar_files:\n",
        "        try:\n",
        "            df = pd.read_csv(file, usecols=['listing_id'])\n",
        "            period_ids.append(set(df['listing_id'].unique()))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {os.path.basename(file)}: {str(e)}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    # Find IDs common to ALL 4 periods\n",
        "    common_ids = set.intersection(*period_ids)\n",
        "    if not common_ids:\n",
        "        print(f\"❌ No listings common to all 4 periods in {city_folder}\")\n",
        "        return pd.DataFrame()\n",
        "    # Second pass: Process data for validated IDs\n",
        "    final_dfs = []\n",
        "    for file in calendar_files:\n",
        "        df = pd.read_csv(file, usecols=['listing_id', 'date', 'available'])\n",
        "        df = df[df['listing_id'].isin(common_ids)]\n",
        "\n",
        "        # Filter by date range\n",
        "        period = file.split(\"_\")[-1].split(\".\")[0]\n",
        "        start, end = DATE_RANGES[period]\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        df = df[(df['date'] >= start) & (df['date'] <= end)]\n",
        "\n",
        "        final_dfs.append(df)\n",
        "\n",
        "    return pd.concat(final_dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "9VZ-gUPFuqdc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# 3. Listing Data Processing\n",
        "# ==============================================\n",
        "def process_listings(city_folder: str, valid_ids: list) -> pd.DataFrame:\n",
        "    \"\"\"Process and clean listing data with optimized memory usage\"\"\"\n",
        "    listings_path = os.path.join(city_folder, \"listings.csv\")\n",
        "\n",
        "    # Selected columns (reduces memory usage by 60%)\n",
        "    cols = [\n",
        "        'id', 'neighbourhood_cleansed', 'latitude', 'longitude',\n",
        "        'property_type', 'room_type', 'accommodates', 'bedrooms',\n",
        "        'beds', 'price', 'review_scores_rating', 'instant_bookable', 'amenities',\n",
        "        'description', 'host_response_time', 'host_is_superhost', 'bathrooms', 'bathrooms_text'\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Read listings data with selected columns\n",
        "        df = pd.read_csv(listings_path, usecols=cols)\n",
        "\n",
        "        # Filter listings to include only those with valid IDs\n",
        "        return df[df['id'].isin(valid_ids)]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing listings: {str(e)}\")\n",
        "        return pd.DataFrame()\n"
      ],
      "metadata": {
        "id": "npTpcsK3u-W-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==============================================\n",
        "# 4. Main Execution Flow\n",
        "# ==============================================\n",
        "def main():\n",
        "    all_listings = []\n",
        "    all_calendars = []\n",
        "\n",
        "    for city in CITIES:\n",
        "        city_path = os.path.join(BASE_DIR, city)\n",
        "        print(f\"\\nProcessing: {city.upper()}\")\n",
        "\n",
        "        # Process calendar data\n",
        "        calendar_data = process_calendar(city_path)\n",
        "        if calendar_data.empty:\n",
        "            print(f\"Skipped {city} - no valid calendar data\")\n",
        "            continue\n",
        "\n",
        "        # Process listings\n",
        "        valid_ids = calendar_data['listing_id'].unique()\n",
        "        listing_data = process_listings(city_path, valid_ids)\n",
        "\n",
        "        if not listing_data.empty:\n",
        "            # Add city identifiers\n",
        "            calendar_data['city'] = city\n",
        "            listing_data['city'] = city\n",
        "\n",
        "            # Store results\n",
        "            all_calendars.append(calendar_data)\n",
        "            all_listings.append(listing_data)\n",
        "            print(f\"Added {len(listing_data)} listings\")\n",
        "        else:\n",
        "            print(f\"Skipped {city} - no valid listings\")\n",
        "    # Combine and save all data\n",
        "    if all_listings:\n",
        "        final_listings = pd.concat(all_listings, ignore_index=True)\n",
        "        final_listings.to_csv(\"all_listings.csv\", index=False)\n",
        "        print(\"\\nSaved listings data: all_listings.csv\")\n",
        "\n",
        "    if all_calendars:\n",
        "        final_calendars = pd.concat(all_calendars, ignore_index=True)\n",
        "        final_calendars.to_csv(\"all_calendars.csv\", index=False)\n",
        "        print(\"Saved calendar data: all_calendars.csv\")"
      ],
      "metadata": {
        "id": "PMFsoZBivFsw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==============================================\n",
        "# 5. Run the Pipeline\n",
        "# ==============================================\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "w1WsmgncvIrP",
        "outputId": "7af3018d-05d8-43f4-ac28-cfaa642f43e0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: QUEBEC_CITY\n",
            "Added 1619 listings\n",
            "\n",
            "Processing: VICTORIA\n",
            "Added 3036 listings\n",
            "\n",
            "Processing: MONTREAL\n",
            "Added 5358 listings\n",
            "\n",
            "Processing: TORONTO\n",
            "Added 14609 listings\n",
            "\n",
            "Processing: OTTAWA\n",
            "Added 1900 listings\n",
            "\n",
            "Processing: VANCOUVER\n",
            "Added 4164 listings\n",
            "\n",
            "Processing: WINNIPEG\n",
            "Added 1079 listings\n",
            "\n",
            "Processing: NEW_BRUNSWICK\n",
            "Added 2969 listings\n",
            "\n",
            "Saved listings data: all_listings.csv\n",
            "Saved calendar data: all_calendars.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# 6. Test count unique ID in all_listing dataset and listing_ID in all_calendar dataset (must to be equal)\n",
        "# ==============================================\n",
        "# Count unique listing_id in all_calendars.csv\n",
        "df = pd.read_csv(\"all_calendars.csv\")\n",
        "print(df['listing_id'].nunique())\n",
        "\n",
        "# Count id in all_listing.csv\n",
        "df = pd.read_csv(\"all_listings.csv\")\n",
        "print(df['id'].nunique())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jA6xOsWMpP3N",
        "outputId": "f687e687-6e28-42a9-f0ef-4773ebea2b14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34734\n",
            "34734\n"
          ]
        }
      ]
    }
  ]
}